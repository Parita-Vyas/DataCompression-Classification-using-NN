{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "#from keras.datasets import cifar10  \n",
    "(x_train_old, y_train_old), (x_test_old, y_test_old) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Traning data shape:', x_train_old.shape)\n",
    "print('Testing data shape:', x_test_old.shape)\n",
    "\n",
    "y_train_old.shape,y_test_old.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "\n",
    "for i in range(50000):\n",
    "    if (y_train_old[i]==3) or (y_train_old[i]==5):\n",
    "        y_train.append(y_train_old[i])\n",
    "        #x_train.append([x_train_old[i*500:(i+1)*500]])\n",
    "        x_train.append(x_train_old[i])\n",
    "        #print(len(x_train))\n",
    "        \n",
    "for i in range(10000):\n",
    "    if (y_test_old[i]==3) or (y_test_old[i]==5):\n",
    "        y_test.append(y_test_old[i])\n",
    "        x_test.append(x_test_old[i])\n",
    "        \n",
    "        #print(len(x_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_new = np.array(x_train, dtype=object)\n",
    "y_train_new = np.array(y_train, dtype=object)\n",
    "x_train_new = x_train_new[:8000, :32, :32 , :3]\n",
    "y_train_new = y_train_new[:8000, :1]\n",
    "\n",
    "x_test_new = np.array(x_test, dtype=object)\n",
    "y_test_new = np.array(y_test, dtype=object)\n",
    "x_train_new.shape, y_train_new.shape,x_test_new.shape, y_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "label_dict = {\n",
    " 0: 'airplane',\n",
    " 1: 'automobile',\n",
    " 2: 'bird',\n",
    " 3: 'cat',\n",
    " 4: 'deer',\n",
    " 5: 'dog',\n",
    " 6: 'frog',\n",
    " 7: 'horse',\n",
    " 8: 'ship',\n",
    " 9: 'truck',\n",
    "}\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the 20th/any image in training data\n",
    "plt.subplot(121)\n",
    "curr_img = np.reshape(x_train[20], (32,32,3))\n",
    "plt.imshow(curr_img)\n",
    "print(plt.title(\"(Label: \" + str(label_dict[y_train[20][0]]) + \")\"))\n",
    "\n",
    "# Display the sixth/any image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(x_test[6],(32,32,3))\n",
    "plt.imshow(curr_img)\n",
    "print(plt.title(\"(Label: \" + str(label_dict[y_test[6][0]]) + \")\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dataframe\n",
    "x_train_flat = x_train_new.reshape(-1,3072)\n",
    "feat_cols = ['pixel'+str(i) for i in range(x_train_flat.shape[1])]\n",
    "df_cifar = pd.DataFrame(x_train_flat,columns=feat_cols)\n",
    "df_cifar['label'] = y_train_new\n",
    "print('Size of the dataframe: {}'.format(df_cifar.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_cifar = PCA(n_components=2)\n",
    "principalComponents_cifar = pca_cifar.fit_transform(df_cifar.iloc[:,:-1])\n",
    "\n",
    "principal_cifar_Df = pd.DataFrame(data = principalComponents_cifar\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "principal_cifar_Df['y'] = y_train_new\n",
    "principal_cifar_Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variance\n",
    "print('Explained variation per principal component: {}'.format(pca_cifar.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(\n",
    "    x=\"principal component 1\", y=\"principal component 2\",\n",
    "    hue=\"y\",\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    data=principal_cifar_Df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new = x_test_new/255.0\n",
    "x_test_new = x_test_new.reshape(-1,32,32,3)\n",
    "x_test_flat = x_test_new.reshape(-1,3072)\n",
    "\n",
    "#make the instance of the PCA model.\n",
    "pca = PCA(0.9)\n",
    "pca.fit(x_train_flat)\n",
    "PCA(copy=True, iterated_power='auto', n_components=0.9, random_state=None,\n",
    "  svd_solver='auto', tol=0.0, whiten=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimention reduction\n",
    "pca.n_components_\n",
    "train_img_pca = pca.transform(x_train_flat)\n",
    "test_img_pca = pca.transform(x_test_flat)\n",
    "y_train = y_train[:8000]\n",
    "train_img_pca.shape, test_img_pca.shape, len(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#work on model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import utils as np_utils\n",
    "#from tensorflow.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 6\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='relu', input_shape=(87,)))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "#y_train = tf.reshape(y_train, [2000, 1])\n",
    "#train_img_pca = tf.convert_to_tensor(train_img_pca, dtype=tf.float32)\n",
    "history = model.fit(train_img_pca, y_train,batch_size=batch_size,epochs=epochs,verbose=1,\n",
    "                    validation_data=(test_img_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_img_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_pca[0], train_img_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img_pca.tolist()\n",
    "train_img_pca = np.array(train_img_pca)\n",
    "train_img_pca.resize(8000,32,32,1,refcheck=False)\n",
    "y_train = np.array(y_train)\n",
    "y_train.resize(8000,1,refcheck=False)\n",
    "y_train.shape,train_img_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import random\n",
    "import cv2\n",
    "IMG_SIZE = 32\n",
    "#train_img_pca.resize(32,32,3)\n",
    "#random.shuffle(train_img_pca)\n",
    "\n",
    "\n",
    "print(train_img_pca[0].reshape(-1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "train_img_pca = np.array(train_img_pca).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(train_img_pca, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "train_img_pca = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, train_img_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "train_img_pca = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "\n",
    "train_img_pca = train_img_pca/255.0\n",
    "\n",
    "train_img_pca = np.array(train_img_pca).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=train_img_pca.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            model.fit(train_img_pca, \n",
    "                      y_train,\n",
    "                      batch_size=32,\n",
    "                      epochs=25,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])\n",
    "\n",
    "model.save('is_Cat_or_Dog.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "#print(model.summary())\n",
    "\n",
    "class_category = [\"Dog\", \"Cat\"]\n",
    "\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50  # 50 in txt-based\n",
    "\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    #new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('is_Cat_or_Dog.model')\n",
    "\n",
    "prediction = model.predict([prepare('D:/Image_Dataset/CatDogwithNN/test_set/test_set/cats/cat.4013.jpg')])\n",
    "print(prediction,'\\n')  # will be a list in a list.\n",
    "\n",
    "print(class_category[int(prediction[0][0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_array, cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
